---
title: "Project"
author: "Kameni"
date: "Sunday, December 21, 2014"
output: html_document
---
### Synopsis
 One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.
 The goal of the project is to predict the manner in which they did the exercice with the help of Machine Learning algorithm.


```{r, }
library(caret,quietly=TRUE)
library(randomForest,quietly=TRUE) 
```

####1 Data Loading & Explorating
First we want to load the data sets into R 
```{r}

trainingDf<-read.csv("./pml-training.csv", na.strings=c("", "NA", "NULL"))
dim(trainingDf)# Check number of variables and observations

testDf<-read.csv("./pml-testing.csv", na.strings=c("", "NA", "NULL"))
dim(testDf)# Check number of variables and observations


```


####2 Data Processing
in this part we face 2 problems:a) the missing values and b) the fact that the data set contains irrelevant variables.

#####a-) Processing missing values
we decide to Delete columns that contains missing values.

```{r}
trainingDf<-trainingDf[,colSums(is.na(trainingDf)) == 0];dim(trainingDf)
testDf <-testDf[,colSums(is.na(testDf)) == 0];dim(testDf)
```


#####b-) Processing irrelevant variables
As the first 7 columns are non-numeric non-integer, we decide to delete them.
```{r}
trainingDf <-trainingDf[,-c(1:7)];dim(trainingDf)
testDf <-testDf[,-c(1:7)];dim(testDf)
```


####3 Creating training and cross-validation sets
We have modified the training data(trainingDf). Now we will split the object **trainingDf** into **"train.Sub.trainingDf"(70%)** and **“test.Sub.trainingDf”(30%)**.     
```{r}
set.seed(1442)
data <- createDataPartition(y=trainingDf$classe, p=0.70, list=FALSE)
train.Sub.trainingDf <- trainingDf[data, ];dim(train.Sub.trainingDf)
test.Sub.trainingDf<- trainingDf[-data, ];dim(test.Sub.trainingDf)

```


#### 4 Predicting Model

predicting with random forest
```{r}
model <- randomForest(classe ~. , data=train.Sub.trainingDf, method="class")

# perform the Prediction
prediction <- predict(model, test.Sub.trainingDf, type = "class")

# Test the prediction:
confusionMatrix(prediction, test.Sub.trainingDf$classe)

```


####5 Analizing the Error

 -The accuracy of the model is 0.993(99,3%)
 
 -The expected out-of-sample errorr based on our fitted model applied to the cross validation dataset is 0.007(0.7%).


 we can expect that very few, or  may be none, of the test samples will be missclassified with an accuracy above 99% on our cross-validation data.

####6 Predicted Results

Finally, we apply the Random Forest algorithm to the original testing dataset,to predict the outcome

```{r}
endPrediction <- predict(model, testDf, type="class")
endPrediction
```

